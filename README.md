# Blog Generator with LangGraph

An intelligent blog generation system that uses LangGraph workflows, LLM-based routing, and parallel web research to create high-quality, well-researched articles.

## ğŸŒŸ Features

- **6-Node Workflow**: Keywords â†’ Search â†’ Outlines â†’ Router â†’ Article â†’ Router â†’ Complete
- **LLM-Based Routing**: Intelligent approval/edit decisions using natural language
- **Parallel Web Search**: Simultaneous Tavily searches for multiple keywords
- **JSON-Only Responses**: Structured, parseable outputs from all LLM calls
- **Comprehensive Logging**: Full input/output logging for debugging and monitoring
- **Stateful Workflows**: Thread-based state management with checkpointing
- **Citation Support**: Automatic source citations in generated articles

## ğŸ“‹ Requirements

- Python 3.8+
- Google Gemini API key
- Tavily API key

## ğŸš€ Quick Start

1. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

2. **Set environment variables** in `.env`:
   ```
   GOOGLE_API_KEY=your_google_api_key
   TAVILY_API_KEY=your_tavily_api_key
   ```

3. **Start the server**:
   ```bash
   python src/main.py
   ```

4. **Run tests**:
   ```bash
   python test_workflow.py
   ```

## ğŸ“š Documentation

- **[QUICK_START.md](QUICK_START.md)** - Get started in 5 minutes
- **[WORKFLOW.md](WORKFLOW.md)** - Complete workflow documentation
- **[IMPLEMENTATION_SUMMARY.md](IMPLEMENTATION_SUMMARY.md)** - Technical implementation details

## ğŸ”„ Workflow Overview

```
POST /generate (topic, tone, length)
    â†“
Node 1: Generate 3 Keywords
    â†“
Node 2: Parallel Web Search (3 keywords)
    â†“
Node 3: Generate Outlines + Title
    â†“
â† Returns outlines to user â†’
    â†“
POST /user_input (feedback)
    â†“
Node 4: Router (LLM decides APPROVE or EDIT)
    â”œâ”€ EDIT â†’ Back to Node 3
    â””â”€ APPROVE â†’ Node 5: Write Full Article
         â†“
    â† Returns article to user â†’
         â†“
    POST /user_input (feedback)
         â†“
    Node 6: Router (LLM decides APPROVE or EDIT)
         â”œâ”€ EDIT â†’ Back to Node 5
         â””â”€ APPROVE â†’ END (Complete)
```

## ğŸ¯ API Endpoints

### POST /generate
Generate article outlines from a topic.

**Request**:
```json
{
  "thread_id": "unique-session-id",
  "topic": "AI in Healthcare",
  "tone": "professional",
  "length": "medium"
}
```

**Response**:
```json
{
  "status": "ok",
  "current_stage": "outlines",
  "keywords": "AI diagnostics, machine learning healthcare, patient care AI",
  "outlines_json": {
    "title": "The Future of AI in Healthcare",
    "outlines": [
      {"section": "Introduction", "description": "Overview of AI in healthcare"},
      {"section": "AI in Diagnostics", "description": "How AI improves diagnosis"}
    ]
  }
}
```

### POST /user_input
Provide feedback to continue the workflow.

**Request**:
```json
{
  "thread_id": "unique-session-id",
  "user_feedback": "looks good, proceed"
}
```

**Response** (after article generation):
```json
{
  "status": "ok",
  "current_stage": "draft",
  "draft_article": {
    "title": "The Future of AI in Healthcare",
    "content": "# The Future of AI in Healthcare\n\n## Introduction\n..."
  }
}
```

## ğŸ” Logging

All execution details are logged to `logs/app.log`:

- Node inputs and outputs
- Full LLM prompts
- Raw LLM responses
- Routing decisions
- API request/response details
- Error traces

## ğŸ§ª Testing

Run the automated test suite:

```bash
python test_workflow.py
```

Tests include:
1. Complete happy path (approve all)
2. Edit outlines scenario
3. Edit article scenario

## ğŸ“ Project Structure

```
bolg_generator/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py          # FastAPI server
â”‚   â”œâ”€â”€ graph.py         # LangGraph workflow definition
â”‚   â””â”€â”€ nodes.py         # Node implementations
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ prompts.py       # LLM prompts (all JSON-enforced)
â”‚   â”œâ”€â”€ tools.py         # Tavily search utilities
â”‚   â””â”€â”€ model_config.py  # LLM configuration
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ app.log          # Execution logs
â”œâ”€â”€ test_workflow.py     # Automated tests
â”œâ”€â”€ WORKFLOW.md          # Detailed workflow docs
â”œâ”€â”€ QUICK_START.md       # Quick start guide
â””â”€â”€ README.md            # This file
```

## ğŸ› ï¸ Technology Stack

- **FastAPI**: REST API server
- **LangGraph**: Workflow orchestration
- **LangChain**: LLM integration
- **Google Gemini**: LLM provider
- **Tavily**: Web search API
- **Pydantic**: Data validation

## ğŸ’¡ Key Features Explained

### JSON-Only LLM Responses
All prompts enforce strict JSON output with no markdown code blocks, ensuring reliable parsing.

### LLM-Based Routing
Router nodes use the LLM to understand natural language feedback and decide whether to approve or request edits.

### Parallel Web Search
Multiple keywords are searched simultaneously using ThreadPoolExecutor for faster research.

### Context Management
Tone, length, and web content are preserved throughout the workflow for consistent article generation.

### Comprehensive Logging
Every node logs:
- All inputs
- Full LLM prompts
- Raw LLM responses
- Parsed outputs
- Execution time

## ğŸ¤ Contributing

This is a production-ready blog generator. To extend:

1. Add new nodes in `src/nodes.py`
2. Update workflow in `src/graph.py`
3. Add prompts in `utils/prompts.py`
4. Test with `test_workflow.py`

## ğŸ“ License

MIT License

## ğŸ™‹ Support

Check the logs at `logs/app.log` for detailed debugging information.

---

**Status**: âœ… Production Ready

**Last Updated**: 2025-10-01
